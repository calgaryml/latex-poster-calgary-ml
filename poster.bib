@misc{yani2022,
  author       = {Evci, Utku and
                  Ioannou, Yani and
                  Keskin, cem and
                  Dauphin, Yann},
  title        = {{Gradient Flow in Sparse Neural Networks and How 
                   Lottery Tickets Win - AAAI 2022 Poster}},
  month        = feb,
  year         = 2022,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.6047581}
}

@INPROCEEDINGS{storing_sparse_mats,  
author={Shahnaz, Rukhsana and Usman, Anila and Chughtai, Imran R.},  
booktitle={2005 Pakistan Section Multitopic Conference},   
title={Review of Storage Techniques for Sparse Matrices},   
year={2005},  
volume={},  
number={},  
pages={1-7},  doi={10.1109/INMIC.2005.334453}
}

@inproceedings{
mihai2021,
title={The future is log-Gaussian: ResNets and their infinite-depth-and-width limit at initialization},
author={Mufan Li and Mihai Nica and Daniel M. Roy},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021}
}

@inproceedings{collegialnetworks,
 author = {Littwin, Etai and Myara, Ben and Sabah, Sima and Susskind, Joshua and Zhai, Shuangfei and Golan, Oren},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {18738--18748},
 publisher = {Curran Associates, Inc.},
 title = {Collegial Ensembles},
 volume = {33},
 year = {2020}
}



@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}



@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}




@inproceedings{he_deep_2016,
	address = {Las Vegas, NV, USA},
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	isbn = {978-1-4673-8851-1},
	doi = {10.1109/CVPR.2016.90},
	language = {en},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = jun,
	year = {2016},
	pages = {770--778},
}


@techreport{krizhevsky_learning_2009,
	title = {Learning multiple layers of features from tiny images},
	author = {Krizhevsky, Alex},
	year = {2009},
	ulr={https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf},
    institution = {University of Toronto}
}


@inproceedings{jayakumar_top-kast_2020,
	title = {Top-{KAST}: {Top}-{K} {Always} {Sparse} {Training}},
	volume = {33},
	shorttitle = {Top-{KAST}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Jayakumar, Siddhant and Pascanu, Razvan and Rae, Jack and Osindero, Simon and Elsen, Erich},
	year = {2020},
	pages = {20744--20754},
}


@techreport{evci_rigging_2021,
	title = {Rigging the {Lottery}: {Making} {All} {Tickets} {Winners}},
	shorttitle = {Rigging the {Lottery}},
	number = {arXiv:1911.11134},
	institution = {arXiv},
	author = {Evci, Utku and Gale, Trevor and Menick, Jacob and Castro, Pablo Samuel and Elsen, Erich},
	month = jul,
	year = {2021},
	doi = {10.48550/arXiv.1911.11134},
	note = {arXiv:1911.11134},
}


@article{mocanu_scalable_2018,
	title = {Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science},
	volume = {9},
	issn = {2041-1723},
	doi = {10.1038/s41467-018-04316-3},
	language = {en},
	number = {1},
	journal = {Nature Communications},
	author = {Mocanu, Decebal Constantin and Mocanu, Elena and Stone, Peter and Nguyen, Phuong H. and Gibescu, Madeleine and Liotta, Antonio},
	month = dec,
	year = {2018},
	pages = {2383},
}


@techreport{dettmers_sparse_2019,
	title = {Sparse {Networks} from {Scratch}: {Faster} {Training} without {Losing} {Performance}},
	shorttitle = {Sparse {Networks} from {Scratch}},
	number = {arXiv:1907.04840},
	institution = {arXiv},
	author = {Dettmers, Tim and Zettlemoyer, Luke},
	month = aug,
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	annote = {Comment: 9 page NeurIPS 2019 submission}
}



@article{dai_nest_2019,
	title = {{NeST}: {A} {Neural} {Network} {Synthesis} {Tool} {Based} on a {Grow}-and-{Prune} {Paradigm}},
	volume = {68},
	issn = {1557-9956},
	shorttitle = {{NeST}},
	doi = {10.1109/TC.2019.2914438},
	number = {10},
	journal = {IEEE Transactions on Computers},
	author = {Dai, Xiaoliang and Yin, Hongxu and Jha, Niraj K.},
	month = oct,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Computers},
	keywords = {Architecture synthesis, Biological neural networks, Computer architecture, Correlation, grow-and-prune paradigm, Manganese, network parameters, neural network, Neurons, Tools, Training},
	pages = {1487--1497},
}


@techreport{lee_snip_2019,
	title = {{SNIP}: {Single}-shot {Network} {Pruning} based on {Connection} {Sensitivity}},
	shorttitle = {{SNIP}},
	number = {arXiv:1810.02340},
	institution = {arXiv},
	author = {Lee, Namhoon and Ajanthan, Thalaiyasingam and Torr, Philip H. S.},
	month = feb,
	year = {2019},
	note = {arXiv:1810.02340 [cs]
type: article},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	annote = {Comment: ICLR 2019},
}


@inproceedings{elsen2020cvpr,
  author = {Elsen, Erich and Dukhan, Marat and Gale, Trevor and Simonyan, Karen},
  title = {Fast Sparse ConvNets},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2020},
  EVENTDATE={2020-06-14/2020-06-19},
  VENUE={Seattle, WA, USA},
}

@misc{gale2020sparse,
      title={Sparse GPU Kernels for Deep Learning}, 
      author={Trevor Gale and Matei Zaharia and Cliff Young and Erich Elsen},
      year={2020},
      arxivid={2006.10901},
      eprint={2006.10901},
      eprinttype={arXiv},
}

@misc{child_generating_2019,
	title = {Generating {Long} {Sequences} with {Sparse} {Transformers}},
	url = {http://arxiv.org/abs/1904.10509},
	language = {en},
	publisher = {arXiv},
	author = {Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
	month = apr,
	year = {2019},
	note = {Number: arXiv:1904.10509 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{you_drawing_2020,
  title      = {Drawing {Early}-{Bird} {Tickets}: {Toward} {More} {Efficient} {Training} of {Deep} {Networks}},
  shorttitle = {Drawing {Early}-{Bird} {Tickets}},
  abstract   = {(Frankle \& Carbin, 2019) shows that there exist winning tickets (small but critical subnetworks) for dense, randomly initialized networks, that can be trained alone to achieve comparable accuracies...},
  language   = {en},
  author     = {You, Haoran and Li, Chaojian and Xu, Pengfei and Fu, Yonggan and Wang, Yue and Chen, Xiaohan and Baraniuk, Richard G. and Wang, Zhangyang and Lin, Yingyan},
  year       = {2020},
  booktitle     = {International Conference on Learning Representations}
}


@inproceedings{mostafa_parameter_2019,
  title     = {Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization},
  language  = {en},
  booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
  publisher = {PMLR},
  author    = {Mostafa, Hesham and Wang, Xin},
  month     = may,
  year      = {2019},
  note      = {ISSN: 2640-3498},
  pages     = {4646--4655}
}

@inproceedings{zhou2021learning,
title={Learning N:M Fine-grained Structured Sparse Neural Networks From Scratch},
author={Aojun Zhou and Yukun Ma and Junnan Zhu and Jianbo Liu and Zhijie Zhang and Kun Yuan and Wenxiu Sun and Hongsheng Li},
booktitle={International Conference on Learning Representations},
year={2021},
}

@TECHREPORT{NvidiaA100, 
  TITLE = {NVIDIA {A}100 {T}ensor {C}ore {GPU} {A}rchitecture},
  AUTHOR={Nvidia},
  INSTITUTION = {Nvidia},
  YEAR = {2020},
}

@inproceedings{han2015learning,
  title={Learning both weights and connections for efficient neural network},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
  booktitle={Advances in neural information processing systems},
  year={2015}
}
@inproceedings{deepcompression,
  author    = {Song Han and
               Huizi Mao and
               William J. Dally},
  title     = {Deep Compression: Compressing Deep Neural Network with Pruning, Trained
               Quantization and Huffman Coding},
  booktitle = {4th International Conference on Learning Representations, {ICLR} 2016,
               San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  year      = {2016},
}

@inproceedings{
grasp,
title={Picking Winning Tickets Before Training by Preserving Gradient Flow},
author={Chaoqi Wang and Guodong Zhang and Roger Grosse},
booktitle={ICLR},
year={2020}
}

@unpublished{bengio2013ste,
  doi = {10.48550/ARXIV.1308.3432},
  author = {Bengio, Yoshua and LÃ©onard, Nicholas and Courville, Aaron},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation},
  note = {arXiv pre-print},
  publisher = {arXiv},
  eprint = {1308.3432},
  archivePrefix={arXiv},
  year = {2013}
}

@article{imagenet,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {ImageNet Large Scale Visual Recognition Challenge},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)}
}

@misc{goyal2018,
	title = {Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour},
	publisher = {arXiv},
	author = {Goyal, Priya and DollÃ¡r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
	month = apr,
	year = {2018},
	eprint = {1706.02677v2},
}

@misc{nollied, 
    author = {McCreary, Dyllan},
    title = {PyTorch Implementation of Rigging the Lottery: Making All Tickets Winners}, 
    year = {2020}, 
    month = {Nov},
    note = {Re-implementation/extension of the work done by Google Research: https://github.com/google-research/rigl}
}

@inproceedings{szegedy_rethinking_2016,
	title = {Rethinking the {Inception} {Architecture} for {Computer} {Vision}},
	doi = {10.1109/CVPR.2016.308},
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	month = jun,
	year = {2016},
	note = {ISSN: 1063-6919},
	keywords = {Benchmark testing, Computational efficiency, Computational modeling, Computer architecture, Computer vision, Convolution, Training},
	pages = {2818--2826},
    booktitle={IEEE Conference on Computer Vision and Pattern Recognition}
}


@misc{zagoruyko_wide_2017,
	title = {Wide {Residual} {Networks}},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Zagoruyko, Sergey and Komodakis, Nikos},
	year = {2017},
	note = {arXiv:1605.07146},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}


@misc{sparseprop,
	title = {{SparseProp}: {Efficient} {Sparse} {Backpropagation} for {Faster} {Training} of {Neural} {Networks}},
	url = {http://arxiv.org/abs/2302.04852},
	doi = {10.48550/arXiv.2302.04852},
	urldate = {2023-03-06},
	publisher = {arXiv},
	author = {Nikdan, Mahdi and Pegolotti, Tommaso and Iofinova, Eugenia and Kurtic, Eldar and Alistarh, Dan},
	month = Feb,
	year = {2023},
	note = {arXiv:2302.04852 [cs]},
}


@article{hoefler_sparsity_2021,
	title = {Sparsity in {Deep} {Learning}: {Pruning} and growth for efficient inference and training in neural networks},
	shorttitle = {Sparsity in {Deep} {Learning}},
	url = {http://arxiv.org/abs/2102.00554},
	urldate = {2022-03-31},
	journal = {arXiv:2102.00554 [cs]},
	author = {Hoefler, Torsten and Alistarh, Dan and Ben-Nun, Tal and Dryden, Nikoli and Peste, Alexandra},
	month = jan,
	year = {2021},
	note = {arXiv: 2102.00554},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Hardware Architecture},
}

@inproceedings{yang_get_2022,
	title = {Get {More} at {Once}: {Alternating} {Sparse} {Training} with {Gradient} {Correction}},
	shorttitle = {Get {More} at {Once}},
	url = {https://openreview.net/forum?id=lYZQRpqLesi},
	language = {en},
	urldate = {2023-03-16},
	author = {Yang, Li and Meng, Jian and Seo, Jae-sun and Fan, Deliang},
	month = oct,
	year = {2022},
        booktitle = {Proceedings of the Neural Information Processing Systems Conference (NeurIPS)},
}

@inproceedings{jiang_exposing_2022,
	title = {Exposing and {Exploiting} {Fine}-{Grained} {Block} {Structures} for {Fast} and {Accurate} {Sparse} {Training}},
	url = {https://openreview.net/forum?id=sFapsu4hYo},
	language = {en},
	urldate = {2023-03-16},
	author = {Jiang, Peng and Hu, Lihan and Song, Shihui},
	month = oct,
	year = {2022},
        booktitle = {Proceedings of the Neural Information Processing Systems Conference (NeurIPS)},
}

@unpublished{dietrich_towards_2022,
	title = {Towards {Structured} {Dynamic} {Sparse} {Pre}-{Training} of {BERT}},
	url = {https://openreview.net/forum?id=-e7awdzWsOc},
	language = {en},
	urldate = {2023-03-16},
	author = {Dietrich, Anastasia S. D. and Gressmann, Frithjof and Orr, Douglas and Chelombiev, Ivan and Justus, Daniel and Luschi, Carlo},
	month = jan,
	year = {2022},
    note={Submitted to the International Conference on Learning Representations}
}

@misc{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	url = {http://arxiv.org/abs/1810.04805},
	doi = {10.48550/arXiv.1810.04805},
	urldate = {2023-03-17},
	publisher = {arXiv},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv:1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{liu_sparse_2021,
	title = {Sparse {Training} via {Boosting} {Pruning} {Plasticity} with {Neuroregeneration}},
	volume = {34},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Liu, Shiwei and Chen, Tianlong and Chen, Xiaohan and Atashgahi, Zahra and Yin, Lu and Kou, Huanyu and Shen, Li and Pechenizkiy, Mykola and Wang, Zhangyang and Mocanu, Decebal Constantin},
	year = {2021},
	pages = {9908--9922},
}

@inproceedings{liu_we_2021,
	title = {Do {We} {Actually} {Need} {Dense} {Over}-{Parameterization}? {In}-{Time} {Over}-{Parameterization} in {Sparse} {Training}},
	shorttitle = {Do {We} {Actually} {Need} {Dense} {Over}-{Parameterization}?},
	url = {https://proceedings.mlr.press/v139/liu21y.html},
	language = {en},
	urldate = {2022-10-05},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Liu, Shiwei and Yin, Lu and Mocanu, Decebal Constantin and Pechenizkiy, Mykola},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {6989--7000},
}


@inproceedings{bellec_deep_2023,
	title = {Deep {Rewiring}: {Training} very sparse deep networks},
	shorttitle = {Deep {Rewiring}},
	url = {https://openreview.net/forum?id=BJ_wN01C-},
	language = {en},
	urldate = {2023-05-12},
	author = {Bellec, Guillaume and Kappel, David and Maass, Wolfgang and Legenstein, Robert},
	month = jan,
	year = {2023},
	keywords = {DST},
    booktitle={International Conference on Learning Representations}
}


@inproceedings{yuan_mest_2021,
	title = {{MEST}: {Accurate} and {Fast} {Memory}-{Economic} {Sparse} {Training} {Framework} on the {Edge}},
	volume = {34},
	shorttitle = {{MEST}},
	url = {https://proceedings.neurips.cc/paper/2021/hash/ae3f4c649fb55c2ee3ef4d1abdb79ce5-Abstract.html},
	urldate = {2022-10-14},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Yuan, Geng and Ma, Xiaolong and Niu, Wei and Li, Zhengang and Kong, Zhenglun and Liu, Ning and Gong, Yifan and Zhan, Zheng and He, Chaoyang and Jin, Qing and Wang, Siyue and Qin, Minghai and Ren, Bin and Wang, Yanzhi and Liu, Sijia and Lin, Xue},
	year = {2021},
	keywords = {DST},
	pages = {20838--20850},
}

@inproceedings{dosovitskiy_image_2021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
    booktitle = {International Conference on Learning Representations},
	url = {https://openreview.net/forum?id=YicbFdNTTy},
	language = {en},
	urldate = {2023-05-12},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = jan,
	year = {2021},
}

@inproceedings{cubuk_randaugment_2020,
	title = {{RandAugment}: {Practical} {Automated} {Data} {Augmentation} with a {Reduced} {Search} {Space}},
	volume = {33},
	shorttitle = {{RandAugment}},
	url = {https://proceedings.neurips.cc/paper/2020/hash/d85b63ef0ccb114d0a3bb7b7d808028f-Abstract.html},
	urldate = {2023-05-13},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Cubuk, Ekin Dogus and Zoph, Barret and Shlens, Jon and Le, Quoc},
	year = {2020},
	pages = {18613--18624},
}


@article{srivastava_dropout_2014,
	title = {Dropout: {A} {Simple} {Way} to {Prevent} {Neural} {Networks} from {Overfitting}},
	volume = {15},
	issn = {1533-7928},
	shorttitle = {Dropout},
	url = {http://jmlr.org/papers/v15/srivastava14a.html},
	number = {56},
	urldate = {2022-09-22},
	journal = {Journal of Machine Learning Research},
	author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	year = {2014},
	pages = {1929--1958},
}

@inproceedings{yun_cutmix_2019,
	address = {Seoul, Korea (South)},
	title = {{CutMix}: {Regularization} {Strategy} to {Train} {Strong} {Classifiers} {With} {Localizable} {Features}},
	isbn = {978-1-72814-803-8},
	shorttitle = {{CutMix}},
	url = {https://ieeexplore.ieee.org/document/9008296/},
	doi = {10.1109/ICCV.2019.00612},
	language = {en},
	urldate = {2023-05-13},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Yun, Sangdoo and Han, Dongyoon and Chun, Sanghyuk and Oh, Seong Joon and Yoo, Youngjoon and Choe, Junsuk},
	month = oct,
	year = {2019},
	pages = {6022--6031},
}

@inproceedings{zhang_mixup_2023,
	title = {mixup: {Beyond} {Empirical} {Risk} {Minimization}},
	shorttitle = {mixup},
	url = {https://openreview.net/forum?id=r1Ddp1-Rb&;noteId=r1Ddp1-Rb),},
    urldate = {2023-05-13},
    booktitle = {International Conference on Machine Learning},
	language = {en},
	author = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and Lopez-Paz, David},
	month = may,
	year = {2023}
}

@misc{torchvision2016,
    title        = {TorchVision: PyTorch's Computer Vision library},
    author       = {Maintainers and Contributors},
    year         = 2016,
    journal      = {GitHub repository},
    publisher    = {GitHub},
    howpublished = {\url{https://github.com/pytorch/vision}}
}


@inproceedings{loshchilov_decoupled_2018,
	title = {Decoupled {Weight} {Decay} {Regularization}},
	url = {https://openreview.net/forum?id=Bkg6RiCqY7},
	language = {en},
	urldate = {2023-05-13},
	author = {Loshchilov, Ilya and Hutter, Frank},
	month = dec,
	year = {2018},
    booktitle={International Conference on Learning Representations}
}


@misc{mishra_accelerating_2021,
	title = {Accelerating {Sparse} {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2104.08378},
	doi = {10.48550/arXiv.2104.08378},
	urldate = {2023-01-03},
	publisher = {arXiv},
	author = {Mishra, Asit and Latorre, Jorge Albericio and Pool, Jeff and Stosic, Darko and Stosic, Dusan and Venkatesh, Ganesh and Yu, Chong and Micikevicius, Paulius},
	month = apr,
	year = {2021},
	note = {arXiv:2104.08378 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Hardware Architecture},
}
